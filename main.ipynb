{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97c57c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition as fr\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33411970",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = fr.load_image_file(\"ali.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae8b11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "locate = fr.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8a3ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face(s). First location:\n",
      "(869, 1401, 1668, 603)\n"
     ]
    }
   ],
   "source": [
    "# Check that at least one face was found before indexing\n",
    "if len(locate) == 0:\n",
    "    print('No faces found in image')\n",
    "else:\n",
    "    print('Found', len(locate), 'face(s). First location:')\n",
    "    print(locate[0])\n",
    "    # Draw a rectangle around the first face and save debug image\n",
    "    top, right, bottom, left = locate[0]\n",
    "    # face_recognition loads images as RGB; OpenCV uses BGR, so convert for saving with cv2\n",
    "    image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    cv2.rectangle(image_bgr, (left, top), (right, bottom), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1e0d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 1919, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_bgr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e87b3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_bgr= cv2.resize(image_bgr, (640, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce51754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image', image_bgr)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29b40229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding and feature extraction\n",
    "encoding_image = fr.face_encodings(image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29304e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06782175  0.1519573   0.06371228  0.01822633 -0.06292582 -0.03813022\n",
      " -0.02592568 -0.05487859  0.17776112 -0.04791391  0.202143    0.03187833\n",
      " -0.20810944  0.10133029 -0.11683221  0.10845546 -0.13854626 -0.03084997\n",
      " -0.11905704 -0.06269778  0.06153662  0.0707965   0.0402205   0.02829828\n",
      " -0.10663827 -0.26395935 -0.09716542 -0.08271527  0.10785515 -0.1051643\n",
      "  0.06063992  0.00351884 -0.1583266  -0.0291784   0.02720127  0.00760293\n",
      "  0.01508736 -0.05581231  0.1771903  -0.02868644 -0.12626022  0.0890078\n",
      " -0.00884946  0.31390962  0.12405138  0.05814483  0.025026   -0.11523858\n",
      "  0.0579194  -0.16205376  0.1521847   0.06346083  0.05254758  0.03865573\n",
      "  0.08420607 -0.17082769  0.00979352  0.17064111 -0.19414115  0.08891568\n",
      "  0.103805    0.00549412  0.0064367  -0.05833983  0.142235    0.05320974\n",
      " -0.12406353 -0.08620534  0.07436661 -0.16088222  0.05986146  0.02421006\n",
      " -0.08481076 -0.171571   -0.2377847   0.11347522  0.49536568  0.20147297\n",
      " -0.15370701  0.04890634 -0.02096045 -0.02336505  0.10952038  0.04112843\n",
      " -0.12112959 -0.04070076 -0.07207654  0.08292954  0.14426878  0.03940278\n",
      " -0.09574261  0.18885462 -0.03930741 -0.07030378 -0.00444677 -0.00577077\n",
      " -0.15580535 -0.0178372  -0.09467757 -0.01756334 -0.0148445  -0.05129049\n",
      " -0.03476801  0.08386312 -0.13137479  0.12303841  0.00452176 -0.03138676\n",
      "  0.01478125  0.11270362 -0.17802422 -0.05357642  0.18205941 -0.22814408\n",
      "  0.20867872  0.11246765  0.03781612  0.16297577  0.0857002   0.10948889\n",
      "  0.04102597  0.05948122 -0.11550258 -0.06657922  0.09796816 -0.03633458\n",
      "  0.17121139  0.00781379]\n"
     ]
    }
   ],
   "source": [
    "print(encoding_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d683368",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetest = fr.load_image_file(\"test.webp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3b4da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetest_encoding= fr.face_encodings(imagetest)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae2ff1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = fr.compare_faces([encoding_image], imagetest_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db0e9bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.False_]\n"
     ]
    }
   ],
   "source": [
    "print(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
